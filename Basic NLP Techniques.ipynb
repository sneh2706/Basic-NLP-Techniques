{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 8), match='facebook'>\n",
      "facebook\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "string = \"facebook is one of the most popular socia media application in India\"\n",
    "pattern1 = \"facebook\"\n",
    "res1 = re.match(pattern1,string)\n",
    "print(res1)\n",
    "print(res1.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(28, 35), match='popular'>\n",
      "popular\n"
     ]
    }
   ],
   "source": [
    "pattern2 = \"popular\"\n",
    "res2 = re.search(pattern2,string)\n",
    "print(res2)\n",
    "print(res2.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['social', 'social']\n",
      "<callable_iterator object at 0x7fd4202dc790>\n",
      "27\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "string = \"facebook is a very popular social site apart from other social sites\"\n",
    "pattern3 = \"social\"\n",
    "res3 = re.findall(pattern3,string)\n",
    "print(res3)\n",
    "\n",
    "res4 = re.finditer(pattern3,string)\n",
    "print(res4)\n",
    "\n",
    "for res in res4:\n",
    "    print(res.start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12-08-2000', '13-04-2005']\n"
     ]
    }
   ],
   "source": [
    "string = \"He was born on 12-08-2000 and first went to school on 13-04-2005\"\n",
    "pattern = \"\\d{2}-\\d{2}-\\d{4}\"\n",
    "res5 = re.findall(pattern,string)\n",
    "print(res5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He was born on Tuesday and first went to school on Tuesday\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(pattern, \"Tuesday\",string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "#tokenization\n",
    "from nltk.tokenize import sent_tokenize\n",
    "text = \"Hey! I am Sneh. Let us start the discussion.\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem(\"playing\"))\n",
    "print(stemmer.stem(\"plays\"))\n",
    "print(stemmer.stem(\"increases\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "print(lemm.lemmatize(\"increases\"))\n",
    "print(lemm.lemmatize(\"running\"))\n",
    "print(lem.lemmatize(\"running\",pos-\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "text = \"facebook is one of the most popular socia media application in India\"\n",
    "tokens = word_tokenize(text)\n",
    "pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wordnet - Vocabulary of all possible words\n",
    "from nltk.corpus import wordnet\n",
    "wordnet.synsets('good') # all synonyms of the word \"good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implementing ngrams\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentence = \"I love to play cricket.\"\n",
    "\n",
    "n = 3\n",
    "ngrams(word_tokenize(sentence),n)\n",
    "for gram in ngrams(word_tokenize(sentence),n):    # printing all ngrams for a given value of n\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
